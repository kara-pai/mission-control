# ğŸ™ï¸ Voice System Setup Guide

**Complete voice integration for Mission Control dashboard:**
- Voice input for notes (browser microphone)
- Voice commands to control dashboard (Web Speech API)
- Email voice message transcription (Gmail + OpenAI Whisper)
- Automated cron transcription processor
- Voice-to-text across all platforms

---

## âœ… What's Installed (Default Configuration)

### 1. **Dashboard Voice Input** âœ… LIVE
- **Location:** Notes tab â†’ ğŸ™ï¸ Record & ğŸ“ Upload buttons
- **Technology:** Browser Web Audio API + Media Recorder
- **Features:**
  - Click "ğŸ™ï¸ Record" to record voice notes
  - Transcription via OpenAI Whisper API (if token configured)
  - Fallback to Web Speech API for local transcription
  - Auto-saves to localStorage
  - Timestamps all voice entries
- **Status:** Ready to use now

### 2. **Voice Commands** âœ… LIVE
- **Location:** ğŸ¤ button (bottom-right corner of dashboard)
- **Technology:** Web Speech API + browser speech synthesis
- **Default Commands:**
  ```
  "go to dashboard"     â†’ Show Dashboard tab
  "go to projects"      â†’ Show Projects tab  
  "go to timeline"      â†’ Show Timeline tab
  "go to notes"         â†’ Show Notes tab
  "new note"            â†’ Open Notes editor
  "clear notes"         â†’ Clear all notes
  "read notes"          â†’ Speak notes aloud
  "search"              â†’ Open search bar
  "what time is it"     â†’ Speak current time
  "help"                â†’ List all commands
  ```
- **How to Use:**
  1. Click ğŸ¤ button (bottom-right)
  2. Say a command (e.g., "go to notes")
  3. Dashboard responds visually + speaks confirmation
  4. Press again to stop listening
- **Status:** Ready to use now (browser dependent)

### 3. **Whisper Transcription CLI** â³ SETUP REQUIRED
- **Location:** `scripts/whisper-transcribe.js`
- **Usage:** 
  ```bash
  export OPENAI_API_KEY=sk-...
  node scripts/whisper-transcribe.js audio.wav [language]
  ```
- **What it does:** Transcribes audio files using OpenAI Whisper API
- **Requires:** OpenAI API key with audio transcription access
- **Status:** Ready but needs API key

### 4. **Email Voice Handler** â³ SETUP REQUIRED
- **Location:** `scripts/email-voice-handler.js`
- **What it does:**
  - Fetches emails with audio attachments from Gmail
  - Downloads voice files automatically
  - Transcribes using Whisper API
  - Saves transcripts to memory logs
- **Usage:**
  ```bash
  export OPENAI_API_KEY=sk-...
  export GMAIL_ACCESS_TOKEN=ya29...
  node scripts/email-voice-handler.js
  ```
- **Status:** Ready but needs credentials

### 5. **Cron Voice Processor** â³ SETUP REQUIRED
- **Location:** `scripts/voice-cron.sh`
- **What it does:**
  - Runs hourly
  - Processes files from `~/.openclaw/MISSION-CONTROL/voice-queue/`
  - Transcribes each audio file
  - Archives processed files
  - Logs everything to `logs/voice-cron.log`
- **Setup (Run once):**
  ```bash
  chmod +x scripts/voice-cron.sh
  
  # Add to crontab (hourly)
  crontab -e
  # Add this line:
  0 * * * * export OPENAI_API_KEY=sk-... && /home/karaai/.openclaw/MISSION-CONTROL/scripts/voice-cron.sh
  ```
- **Status:** Ready but needs cron + API key

---

## ğŸš€ Getting Started (Default Setup)

### **Right Now â€” No Setup Needed:**
1. **Open dashboard:** https://kara-pai.github.io/mission-control/
2. **Try voice commands:** Click ğŸ¤ button â†’ Say "go to notes"
3. **Record a note:** Go to Notes tab â†’ Click ğŸ™ï¸ Record â†’ Speak â†’ See transcript appear

### **To Enable Full Transcription (5 minutes):**

#### Step 1: Get OpenAI API Key
1. Go to https://platform.openai.com/api/keys
2. Create a new API key
3. Copy it (format: `sk-...`)

#### Step 2: Set the environment variable
```bash
export OPENAI_API_KEY=sk-YOUR_KEY_HERE
```

#### Step 3: Test transcription
```bash
# Create a test audio file or use existing one
node /home/karaai/.openclaw/MISSION-CONTROL/scripts/whisper-transcribe.js test.wav
```

#### Step 4: Enable email voice handling
```bash
# If you have Gmail token already configured:
node /home/karaai/.openclaw/MISSION-CONTROL/scripts/email-voice-handler.js
```

#### Step 5: Schedule cron (optional)
```bash
# Edit crontab
crontab -e

# Add this line (runs every hour):
0 * * * * export OPENAI_API_KEY=sk-YOUR_KEY && /home/karaai/.openclaw/MISSION-CONTROL/scripts/voice-cron.sh
```

---

## ğŸ“‹ Commands Reference

### Dashboard Navigation
- "go to dashboard" / "show dashboard"
- "go to projects" / "show projects"
- "go to timeline" / "show timeline"
- "go to notes" / "show notes"

### Notes Management
- "new note" â†’ Open notes editor
- "clear notes" â†’ Clear all notes (with confirmation)
- "read notes" â†’ Speak current notes aloud

### Utilities
- "search" â†’ Focus search bar
- "what time is it" â†’ Speak current time
- "help" / "voice commands" â†’ Show available commands

### Voice Input (Notes Tab)
- ğŸ™ï¸ **Record Button:** Record voice, transcribe, save to notes
- ğŸ“ **Upload Button:** Upload audio file for transcription

---

## ğŸ”§ Configuration

### Default Settings
```javascript
// Voice Recognition (Web Speech API)
language: "en-US"
continuous: true
interim_results: true

// OpenAI Whisper
model: "whisper-1"
language: "en"

// Cron Job
schedule: "0 * * * *" (hourly)
input_dir: "~/.openclaw/MISSION-CONTROL/voice-queue/"
output_dir: "~/.openclaw/MISSION-CONTROL/transcripts/"
```

### Environment Variables
```bash
# Required for transcription
OPENAI_API_KEY=sk-YOUR_KEY

# Optional for email voice handler
GMAIL_ACCESS_TOKEN=ya29...
```

---

## ğŸ“Š File Structure

```
MISSION-CONTROL/
â”œâ”€â”€ index.html                          (Dashboard with voice UI)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ whisper-transcribe.js          (CLI transcription)
â”‚   â”œâ”€â”€ email-voice-handler.js         (Gmail voice processor)
â”‚   â””â”€â”€ voice-cron.sh                  (Cron transcription job)
â”œâ”€â”€ voice-queue/                       (Audio files awaiting transcription)
â”œâ”€â”€ transcripts/                       (Completed transcripts)
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ daily-logs/
â”‚       â”œâ”€â”€ voice-transcripts.md       (All transcriptions)
â”‚       â””â”€â”€ voice-from-email.md        (Email voice messages)
â””â”€â”€ logs/
    â””â”€â”€ voice-cron.log                 (Transcription job logs)
```

---

## âœ¨ Features by Feature

### Feature 1: Voice Input (Notes Tab)
- **Status:** âœ… Active
- **Browser Support:** Chrome, Safari, Firefox, Edge
- **Requires:** Microphone permission
- **Limitation:** Local transcription via Web Speech API (basic)
- **Enhancement:** Add `OPENAI_API_KEY` for Whisper accuracy

### Feature 2: Voice Commands
- **Status:** âœ… Active
- **Browser Support:** Chrome, Safari, Firefox, Edge
- **Requires:** Microphone permission
- **How:** Click ğŸ¤ â†’ Say command â†’ Dashboard responds
- **Customizable:** Edit `commandMap` in voice-commands.js

### Feature 3: CLI Transcription
- **Status:** â³ Ready (needs API key)
- **Command:** `node scripts/whisper-transcribe.js <audio-file>`
- **Output:** `.transcript.txt` file + console output
- **Best For:** Batch processing audio files

### Feature 4: Email Voice Handler
- **Status:** â³ Ready (needs credentials)
- **Watches:** Gmail for audio attachments
- **Processes:** Downloads + transcribes automatically
- **Saves:** To `memory/daily-logs/voice-from-email.md`

### Feature 5: Cron Transcription
- **Status:** â³ Ready (needs setup)
- **Frequency:** Hourly (configurable)
- **Input:** `voice-queue/` directory
- **Output:** `transcripts/` directory + memory logs
- **Logging:** Full audit in `logs/voice-cron.log`

---

## ğŸ¯ Quick Wins

### âœ… Already Working (No API Key)
1. Click ğŸ¤ â†’ Use voice commands to navigate dashboard
2. Notes tab â†’ Click ğŸ™ï¸ Record â†’ Use local speech recognition
3. Speak notes and see them transcribed (basic browser API)

### ğŸš€ With API Key (5 min setup)
1. Set `OPENAI_API_KEY` environment variable
2. Notes tab â†’ Click ğŸ™ï¸ Record â†’ Get accurate OpenAI Whisper transcription
3. Optional: Email voice messages auto-transcribed
4. Optional: Schedule cron for batch processing

---

## ğŸ› Troubleshooting

### "Voice recognition not supported"
- Browser doesn't support Web Speech API
- **Fix:** Use Chrome, Safari, or Edge

### "Microphone access denied"
- Browser permission not granted
- **Fix:** Check browser settings â†’ Allow microphone for this site

### "âŒ Transcription failed"
- API key missing or invalid
- **Fix:** Set `export OPENAI_API_KEY=sk-...` first

### Cron job not running
- Not scheduled in crontab
- **Fix:** Run `crontab -e` and add the line from "Setup" section

### Email voice handler not working
- Gmail token expired or not set
- **Fix:** Refresh token at `~/.openclaw/google-tokens.json`

---

## ğŸ“š Resources

- **Web Speech API:** https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API
- **OpenAI Whisper:** https://platform.openai.com/docs/guides/speech-to-text
- **Media Recorder API:** https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder
- **Gmail API:** https://developers.google.com/gmail/api

---

## ğŸ“ Next Steps

1. **Try it now:** Open dashboard, click ğŸ¤, say "go to notes"
2. **Add API key:** Enable Whisper transcription for accuracy
3. **Set up cron:** Automate batch transcription
4. **Customize commands:** Edit `commandMap` for your workflow

---

**Status:** ğŸŸ¢ VOICE SYSTEM READY  
**Default Setup:** Dashboard voice + Web Speech API (no API key needed)  
**Full Setup:** All 5 features (needs OpenAI API key)

